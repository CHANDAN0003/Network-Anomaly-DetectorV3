Network Anomaly Detector ("Network DNA Fingerprinting")

Project: A modular framework for unsupervised network anomaly detection that treats network flows as "pseudo-DNA" fingerprints and uses autoencoders (optionally LSTM-based) to detect deviations from normal traffic. The repository includes data preprocessing, model training, evaluation, and a live detector for streaming traffic.

Highlights (2025)
- LSTM-based recurrent autoencoder support for time-series (sequence) detection
- Threshold tuning using a calibration set (maximize F1 or target FPR)
- Configurable scalers: StandardScaler, RobustScaler, MinMaxScaler
- Baseline methods included: One-Class SVM and Isolation Forest

Contents
- `src/` - main code: `main.py`, `live_detector.py`, `models/anomaly_detector.py`, and utilities
- `Dataset/` - raw and processed datasets (not tracked in git)
- `model/` - saved model and scaler artifacts (not tracked in git)
- `report/` - saved plots and evaluation figures

Quickstart (Windows cmd)
1. Put your dataset CSVs under `Dataset/raw/Training and Testing Sets/`
   - Example file names used by the pipeline: `UNSW_NB15_training-set.csv`, `UNSW_NB15_testing-set.csv`

2. Create and activate a virtual environment (Windows cmd)

```cmd
python -m venv venv
venv\Scripts\activate
```

3. Install dependencies

If `requirements.txt` exists (recommended):

```cmd
pip install -r requirements.txt
```

Or install core packages manually:

```cmd
pip install tensorflow scikit-learn pandas matplotlib scapy joblib mlflow
```

4. (Optional) Pick a scaler

```cmd
set SCALER_TYPE=robust   # use 'robust' or 'minmax' if desired
```

5. Run the training and evaluation pipeline

```cmd
python src\main.py
```

6. Run the live detector (requires scapy and permissions)

```cmd
python src\live_detector.py
```

What you will get
- `model/autoencoder_model.keras` — trained Keras model (saved by `src/main.py`)
- `model/scaler.joblib` — saved scaler used for preprocessing
- `Dataset/processed/*` — processed CSVs for train/test
- `Dataset/results/anomaly_scores.csv` — anomaly scores and predicted labels
- `report/figures/*` — plots, ROC curves and other evaluation visuals

Notes on datasets and git
- The dataset and model artifacts are intentionally large and excluded from git. `.gitignore` contains entries for `Dataset/` and `model/`.
- If you accidentally committed large files, remove them from the index:

```cmd
git rm -r --cached Dataset
git rm -r --cached model
git commit -m "Remove large dataset and model artifacts; add to .gitignore"
git push
```

Project structure (important files)
- `src/main.py` — entrypoint for preprocessing, training, evaluation, and saving results
- `src/live_detector.py` — lightweight live packet sniffer + preprocessing + model inference
- `src/models/anomaly_detector.py` — model definitions (dense autoencoder, LSTM autoencoder) and helper functions
- `src/utils/` — utility scripts for data processing, metrics, plotting
- `Dataset/raw/` — place raw CSVs here (not in repo)
- `Dataset/processed/` — generated by preprocessing scripts
- `model/` — saved model & scaler files

Usage examples and tips
- To tune threshold using a calibration set, run `src/main.py` with the calibration dataset available under `Dataset/raw/` or using CLI flags if implemented.
- For reproducible runs, set random seeds at the top of `src/main.py` or via environment variables.

Troubleshooting
- If `python` is not recognized on Windows, use the Python launcher: `py -3 -m venv venv` then `venv\Scripts\activate`.
- If `pip install` fails for packages like `tensorflow` or `xgboost`, try installing a compatible wheel for your platform or follow the package-specific instructions.
- Running `live_detector.py` may require administrator/root privileges to sniff packets. On Windows, run the terminal as Administrator.

Development & Contribution
- If you add new datasets or models, document them under `Dataset/` and update this README.
- Consider adding simple helper scripts under `scripts/` (e.g., `run.bat`) to automate environment setup and runs.

License & Contact
- Check the `LICENSE` file in the repository root for licensing information.
- For questions or to contribute, open an issue or PR on the repository.

---

If you'd like, I can also:
- add a `scripts/run.bat` to automate venv creation, dependencies install, and a single-command run
- add a `requirements.txt` snapshot (if you want me to generate one from current imports)
- add short example notebooks to visualize anomaly scores

Completion summary
- I updated the top-level `readme.md` to a concise, structured, and actionable README that preserves the original content while improving clarity and usage instructions.